{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#import math and numpy packages\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# importing the required module \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "'''LOAD THE DATA\n",
    "\n",
    "Keras comes with a library called datasets, which you can use to load\n",
    "datasets out of the box: you download the data from the server and speeds\n",
    "up the process since you no longer have to download the data to your\n",
    "computer. The train and test images along with the labels are loaded\n",
    "and stored in variables train_X, train_Y, test_X, test_Y, respectively.'''\n",
    "from keras.datasets import fashion_mnist\n",
    "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n",
      "Testing data shape :  (10000, 28, 28) (10000,)\n",
      "[9 0 0 3 0 2 7 2 5 5 0 9 5 5 7 9 1 0 6 4 3 1 4 8 4 3 0 2 4 4 5 3 6 6 0 8 5 2 1 6 6 7 9 5 9 2 7 3 0 3 3 3 7 2 2 6 6 8 3 3 5 0 5 5 0 2 0 0 4 1 3 1 6 3 1 4 4 6 1 9 1 3 5 7 9 7 1 7 9 9 9 3 2 9 3 6 4 1 1 8]\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.40-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from ultralytics) (1.23.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from ultralytics) (3.8.4)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from ultralytics) (1.13.1)\n",
      "Collecting torch>=1.8.0 (from ultralytics)\n",
      "  Downloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting tqdm>=4.64.0 (from ultralytics)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from ultralytics) (5.9.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from ultralytics) (2.2.2)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Using cached ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Collecting fsspec (from torch>=1.8.0->ultralytics)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/python3-10_keras_env/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Using cached ultralytics-8.3.40-py3-none-any.whl (898 kB)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchvision-0.20.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Installing collected packages: py-cpuinfo, tqdm, sympy, opencv-python, fsspec, filelock, torch, ultralytics-thop, torchvision, seaborn, ultralytics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 opencv-python-4.10.0.84 py-cpuinfo-9.0.0 seaborn-0.13.2 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 tqdm-4.67.1 ultralytics-8.3.40 ultralytics-thop-2.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for folder in ['train', 'val']:\n",
    "    for catergory in range(10):\n",
    "        os.makedirs(f'./data/{folder}/{catergory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# save the images in a format yolo can use\n",
    "img_num = 0\n",
    "# to run set this number to be > 60k\n",
    "# if you want a subset of the data - then limit this\n",
    "limit = 60000\n",
    "\n",
    "for img, category in zip(train_X, train_Y):\n",
    "    img_path = f\"./data/train/{category}/{img_num}.jpg\"\n",
    "    cv2.imwrite(img_path, img)\n",
    "    img_num += 1\n",
    "    if img_num >= limit:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# save the images in a format yolo can use\n",
    "img_num = 0\n",
    "# to run set this number to be > 10k\n",
    "# if you want a subset of the data - then limit this\n",
    "limit = 10000\n",
    "\n",
    "for img, category in zip(test_X, test_Y):\n",
    "    img_path = f\"./data/val/{category}/{img_num}.jpg\"\n",
    "    cv2.imwrite(img_path, img)\n",
    "    img_num += 1\n",
    "    if img_num >= limit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.10.13 torch-2.5.1 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=./data, epochs=5, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/train... found 60000 images in 10 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/val... found 10000 images in 10 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
      "YOLOv8n-cls summary: 99 layers, 1,451,098 parameters, 1,451,098 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train3', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/train... 60000 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60000/60000 [00:08<00:00, 7251.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/val... 10000 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:01<00:00, 6616.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train3\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      0.858         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [31:41<00:00,  1.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [02:08<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.891      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G     0.3954         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [31:39<00:00,  1.97it/s] \n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [02:09<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.914      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         0G     0.3401         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [1:06:37<00:00,  1.07s/it]   \n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [02:26<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.919      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         0G     0.2992         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [32:15<00:00,  1.94it/s] \n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [02:13<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.927      0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         0G     0.2688         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [43:22<00:00,  1.44it/s]    \n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [02:05<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.934          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 3.612 hours.\n",
      "Optimizer stripped from runs/classify/train3/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from runs/classify/train3/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating runs/classify/train3/weights/best.pt...\n",
      "Ultralytics 8.3.40 ðŸš€ Python-3.10.13 torch-2.5.1 CPU (Apple M2)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,447,690 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/train... found 60000 images in 10 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/val... found 10000 images in 10 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [02:08<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933          1\n",
      "Speed: 0.0ms preprocess, 11.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x2eb49f1f0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9664500057697296\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9333000183105469, 'metrics/accuracy_top5': 0.9995999932289124, 'fitness': 0.9664500057697296}\n",
       "save_dir: PosixPath('runs/classify/train3')\n",
       "speed: {'preprocess': 0.0003133058547973633, 'inference': 11.792788791656495, 'loss': 6.158351898193358e-05, 'postprocess': 8.44717025756836e-05}\n",
       "task: 'classify'\n",
       "top1: 0.9333000183105469\n",
       "top5: 0.9995999932289124"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import YOLO model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-cls.pt') # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "model.train(data='./data', epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40 ðŸš€ Python-3.10.13 torch-2.5.1 CPU (Apple M2)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,447,690 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/train... found 60000 images in 10 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/val... found 10000 images in 10 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/tristan/noodle/strawberry/OilDetector/yolo_proof/data/val... 10000 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [02:19<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933          1\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train32\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9995999932289124"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the model\n",
    "metrics = model.val() # no arguments needed, dataset and settings remembered\n",
    "metrics.top1 # top1 accuracy\n",
    "metrics.top5 # top5 accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-10_keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
